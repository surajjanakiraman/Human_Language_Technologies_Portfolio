# Human_Language_Technologies_Portfolio
This is a sample portfolio for projects in Human Language Technologies

# Portfolio Assignment 0:Getting Started
Description: I have setup the Human Language Technologies Portfolio. This Portfolio will include a list of projects associated with NLP as well as important documentation.
For this assignment, I am attaching a document called
[An Overview of NLP](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022PortfolioAssignment0GettingStarted/sxj170022An%20Overview%20of%20NLP.pdf)


# Portfolio Assignment 1: Text Processing with Python
Brief Description:
(A) The purpose of the program is to process a data.csv file using
Python
(B) You will find [An Overview of Homework 1](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022PortfolioAssignment1/Overview%20of%20Homework1.txt) as well as
the following code files: [Homework1_sxj170022.py](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022PortfolioAssignment1/Homework1_sxj170022.py), [homework1_config.py](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022PortfolioAssignment1/homework1_config.py), and [PersonClass.py](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022PortfolioAssignment1/PersonClass.py).
(C) All of this information in B can be found in the [Homework1 folder](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022PortfolioAssignment1)


# Portfolio Assignment: Chapter 5 Word Guessing Game
Brief Description:
Description: The purpose of the python project is to create a guessing game from a text file. The Python Program reads in the text file anat19.txt, stores the contents of the file in a list,
 processes each token of the file, lemmatizes the tokens to create unique lemmas, gathers all the nouns,
stores the nouns in the dictionary, and creates a guessing game based upon the 50 most common nouns in the dictionary.

How to run: Donwload the files on eLearning and/or Github the
[Config file](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioChapter5_GuessingGame/PortfolioChapter5_GuessingGame_config.py)
the [Main Program](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioChapter5_GuessingGame/sxj170022_PortfolioChapter5_GuessingGame.py), as well as the [data folder](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioChapter5_GuessingGame/data) containing anat19.txt
 make sure to input the following command when running:
 python sxj170022_PortfolioChapter5_GuessingGame.py data/anat19.txt

# Portfolio Assignment: WordNET
Description: The purpose of this assignment is to experiment with
WordNet and SentiWordNet.
Please refer to the [WordNet python file](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_AssignmentWordnet.ipynb) for more details

# Portfolio Assignment: Chapter 8 NGrams
Description: The project involves creating unigram and bigram dictionaries for the following languages: English, French, and Italian. The purpose of the overall project is to calculate the probabilities for each language and get the overall accuracy of correctly classified instances in the test set with respect to the dictionaries.
There are 2 programs for this project:
[Program 1](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioAssignment_NGrams/program1.py) involves building languages models for the 3 languages (English, French, and Italian) and creating unigram and bigram dictionaries from these language models. The program pickles the dictionaries to save execution time in running the project.
[Program 2](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioAssignment_NGrams/program2.py) does the following:
 A. It reads in the pickled dictionaries.
 B. Calculates the probability for each language
 C. Writes the language with the highest probability to a file
 D. Computes and outputs your accuracy as the percentage of correctly classified instances in the test set.

 [Narrative](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioAssignment_NGrams/Ngrams.pdf): Also included is a short narrative about Ngrams.


# Portfolio Assignment: Web Scraper
Description: This project gets a list of URLS from a starter url:
 https://medium.com/. The project scrapes through the list of URLS and outputs a text file called [urls.txt](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioAssignment_WebScraper/Web_scraper/urls.txt). Next, text is scraped from the urls and each text is put into their own files. Since there were 51 urls in urls.txt, you should see 51 different text [files](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/tree/main/sxj170022_PortfolioAssignment_WebScraper/Web_scraper/files) containing text from each url website.
Next a [knowledge base](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioAssignment_WebScraper/Web_scraper/knowledge_base.txt) is created from the texts for all the websites. Note: The knowledge base text file is very large so you may not be able to see it at a first glance on Github.
A [web crawler report](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_PortfolioAssignment_WebScraper/Web_crawler_Report.docx) describes the knowledge base as well as includes the top 10 terms from the knowledge and a sample dialog for the knowledge base


# Portfolio Assignment: Sentence Parsing
Description: For this assignment, I created a fairly complex sentence.  I drew by hand a PSG/constituency tree, a Dependency Parse and a SRL parse for the sentence. You can find the [Sentence Parsing Assignment](https://github.com/surajjanakiraman/Human_Language_Technologies_Portfolio/blob/main/sxj170022_Sentence%20Parsing%20Assignment/sxj170022_SentenceParsingAssignment.pdf) on GitHub
